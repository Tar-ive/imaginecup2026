{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demand Forecasting Model Training\n",
    "\n",
    "This notebook trains a demand forecasting model using purchase order history\n",
    "from Postgres Neon database. The trained model is exported as a pickle file\n",
    "for use by downstream supply chain agents.\n",
    "\n",
    "Upload this file to Google Colab and run it.\n",
    "\n",
    "## Data Summary:\n",
    "- 553 products\n",
    "- 61 purchase orders  \n",
    "- 519 purchase order items\n",
    "- No explicit seasonality data\n",
    "\n",
    "Given the sparse data, we use a hybrid approach:\n",
    "1. XGBoost for products with sufficient history (10+ orders)\n",
    "2. Simple statistics-based fallback for sparse products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "Run this cell first in Colab"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# !pip install psycopg2-binary pandas numpy scikit-learn xgboost sqlalchemy python-dotenv"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Option 1: Using Colab Secrets (Recommended)\n",
    "# from google.colab import userdata\n",
    "# DATABASE_URL = userdata.get('DATABASE_URL')\n",
    "\n",
    "# Option 2: Manual input (for testing)\n",
    "# DATABASE_URL = \"postgresql://user:password@host.neon.tech:5432/dbname?sslmode=require\"\n",
    "\n",
    "# Uncomment and set your DATABASE_URL:\n",
    "DATABASE_URL = input(\"Enter your DATABASE_URL: \")\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT 1\"))\n",
    "        print(\"âœ… Database connection successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Connection failed: {e}\")\n",
    "    raise"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction Queries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Query 1: Historical demand aggregated by product and date\n",
    "DEMAND_HISTORY_QUERY = \"\"\"\n",
    "SELECT \n",
    "    DATE(po.order_date) as order_date,\n",
    "    poi.asin,\n",
    "    p.title as product_name,\n",
    "    p.brand,\n",
    "    SUM(poi.quantity_ordered) as quantity_ordered,\n",
    "    COUNT(DISTINCT po.po_number) as num_orders,\n",
    "    AVG(poi.unit_price) as avg_unit_price,\n",
    "    SUM(poi.line_total) as total_value\n",
    "FROM purchase_order_items poi\n",
    "JOIN purchase_orders po ON poi.po_number = po.po_number\n",
    "JOIN products p ON poi.asin = p.asin\n",
    "WHERE po.order_date IS NOT NULL\n",
    "GROUP BY DATE(po.order_date), poi.asin, p.title, p.brand\n",
    "ORDER BY poi.asin, order_date\n",
    "\"\"\"\n",
    "\n",
    "# Query 2: Current inventory state for all products\n",
    "INVENTORY_QUERY = \"\"\"\n",
    "SELECT \n",
    "    asin,\n",
    "    title,\n",
    "    brand,\n",
    "    quantity_on_hand,\n",
    "    quantity_reserved,\n",
    "    quantity_available,\n",
    "    reorder_point,\n",
    "    reorder_quantity,\n",
    "    lead_time_days,\n",
    "    unit_cost,\n",
    "    market_price,\n",
    "    supplier_id\n",
    "FROM products\n",
    "WHERE is_active = true\n",
    "ORDER BY asin\n",
    "\"\"\"\n",
    "\n",
    "# Query 3: Product order summary (for fallback statistics)\n",
    "PRODUCT_STATS_QUERY = \"\"\"\n",
    "SELECT \n",
    "    poi.asin,\n",
    "    p.title,\n",
    "    p.brand,\n",
    "    COUNT(DISTINCT po.po_number) as total_orders,\n",
    "    SUM(poi.quantity_ordered) as total_quantity,\n",
    "    AVG(poi.quantity_ordered) as avg_quantity_per_order,\n",
    "    STDDEV(poi.quantity_ordered) as std_quantity,\n",
    "    MIN(poi.quantity_ordered) as min_quantity,\n",
    "    MAX(poi.quantity_ordered) as max_quantity,\n",
    "    MIN(po.order_date) as first_order_date,\n",
    "    MAX(po.order_date) as last_order_date\n",
    "FROM purchase_order_items poi\n",
    "JOIN purchase_orders po ON poi.po_number = po.po_number\n",
    "JOIN products p ON poi.asin = p.asin\n",
    "GROUP BY poi.asin, p.title, p.brand\n",
    "ORDER BY total_orders DESC\n",
    "\"\"\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"ðŸ“Š Loading data from Postgres Neon...\")\n",
    "\n",
    "df_demand = pd.read_sql(DEMAND_HISTORY_QUERY, engine)\n",
    "df_inventory = pd.read_sql(INVENTORY_QUERY, engine)\n",
    "df_product_stats = pd.read_sql(PRODUCT_STATS_QUERY, engine)\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Data Summary:\")\n",
    "print(f\"   - Demand records: {len(df_demand)}\")\n",
    "print(f\"   - Active products in inventory: {len(df_inventory)}\")\n",
    "print(f\"   - Products with order history: {len(df_product_stats)}\")\n",
    "\n",
    "# Show top products by order count\n",
    "print(f\"\\nðŸ† Top 10 Products by Order Count:\")\n",
    "print(df_product_stats[['asin', 'title', 'total_orders', 'total_quantity', 'avg_quantity_per_order']].head(10))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis & Validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nðŸ” Data Analysis:\")\n",
    "\n",
    "# Check order history depth\n",
    "order_counts = df_product_stats['total_orders'].describe()\n",
    "print(f\"\\nOrder count distribution:\")\n",
    "print(order_counts)\n",
    "\n",
    "# Identify products with sufficient data for ML\n",
    "MIN_ORDERS_FOR_ML = 5\n",
    "products_ml = df_product_stats[df_product_stats['total_orders'] >= MIN_ORDERS_FOR_ML]['asin'].tolist()\n",
    "products_fallback = df_product_stats[df_product_stats['total_orders'] < MIN_ORDERS_FOR_ML]['asin'].tolist()\n",
    "\n",
    "print(f\"\\nðŸ“Š Training Strategy:\")\n",
    "print(f\"   - Products with ML training ({MIN_ORDERS_FOR_ML}+ orders): {len(products_ml)}\")\n",
    "print(f\"   - Products with statistical fallback: {len(products_fallback)}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def prepare_features(df: pd.DataFrame, asin: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare features for a single product's time series.\n",
    "    Given sparse data, we use minimal but effective features.\n",
    "    \"\"\"\n",
    "    product_df = df[df['asin'] == asin].copy()\n",
    "    \n",
    "    if len(product_df) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    product_df['order_date'] = pd.to_datetime(product_df['order_date'])\n",
    "    product_df = product_df.sort_values('order_date')\n",
    "    \n",
    "    # Temporal features\n",
    "    product_df['day_of_week'] = product_df['order_date'].dt.dayofweek\n",
    "    product_df['day_of_month'] = product_df['order_date'].dt.day\n",
    "    product_df['month'] = product_df['order_date'].dt.month\n",
    "    product_df['is_weekend'] = product_df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    \n",
    "    # Order sequence features (for sparse data)\n",
    "    product_df['order_number'] = range(1, len(product_df) + 1)\n",
    "    \n",
    "    # Lag features (only if enough data)\n",
    "    if len(product_df) >= 3:\n",
    "        product_df['lag_1'] = product_df['quantity_ordered'].shift(1)\n",
    "        product_df['lag_2'] = product_df['quantity_ordered'].shift(2)\n",
    "    \n",
    "    # Rolling statistics\n",
    "    if len(product_df) >= 3:\n",
    "        product_df['rolling_mean_3'] = product_df['quantity_ordered'].rolling(3, min_periods=1).mean()\n",
    "    \n",
    "    # Fill NaN with column mean\n",
    "    product_df = product_df.fillna(product_df.mean(numeric_only=True))\n",
    "    \n",
    "    return product_df"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecaster Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class DemandForecaster:\n",
    "    \"\"\"\n",
    "    Hybrid demand forecaster for supply chain agents.\n",
    "    \n",
    "    Uses XGBoost for products with sufficient order history,\n",
    "    and statistical methods for sparse data products.\n",
    "    \n",
    "    Outputs:\n",
    "    - Predicted demand (next N days)\n",
    "    - Confidence intervals (lower/upper bounds)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, forecast_horizon: int = 7, min_orders_for_ml: int = 5):\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        self.min_orders_for_ml = min_orders_for_ml\n",
    "        \n",
    "        # Models and statistics storage\n",
    "        self.ml_models: Dict[str, object] = {}\n",
    "        self.product_stats: Dict[str, dict] = {}\n",
    "        \n",
    "        # Feature configuration\n",
    "        self.feature_columns = [\n",
    "            'day_of_week', 'day_of_month', 'month', 'is_weekend',\n",
    "            'order_number', 'lag_1', 'lag_2', 'rolling_mean_3'\n",
    "        ]\n",
    "        \n",
    "        # Metadata\n",
    "        self.metadata = {\n",
    "            'trained_at': None,\n",
    "            'version': '1.0.0',\n",
    "            'forecast_horizon': forecast_horizon,\n",
    "            'ml_products': [],\n",
    "            'fallback_products': [],\n",
    "            'metrics': {}\n",
    "        }\n",
    "    \n",
    "    def train(self, df_demand: pd.DataFrame, df_stats: pd.DataFrame):\n",
    "        \"\"\"Train models for all products.\"\"\"\n",
    "        import xgboost as xgb\n",
    "        \n",
    "        print(\"\\nðŸš€ Training Demand Forecaster...\")\n",
    "        \n",
    "        # Store product statistics for all products (fallback)\n",
    "        for _, row in df_stats.iterrows():\n",
    "            asin = row['asin']\n",
    "            self.product_stats[asin] = {\n",
    "                'avg_quantity': float(row['avg_quantity_per_order']) if pd.notna(row['avg_quantity_per_order']) else 0,\n",
    "                'std_quantity': float(row['std_quantity']) if pd.notna(row['std_quantity']) else 0,\n",
    "                'total_orders': int(row['total_orders']),\n",
    "                'min_quantity': float(row['min_quantity']) if pd.notna(row['min_quantity']) else 0,\n",
    "                'max_quantity': float(row['max_quantity']) if pd.notna(row['max_quantity']) else 0,\n",
    "            }\n",
    "        \n",
    "        # Train ML models for products with sufficient data\n",
    "        ml_candidates = df_stats[df_stats['total_orders'] >= self.min_orders_for_ml]['asin'].tolist()\n",
    "        \n",
    "        for asin in ml_candidates:\n",
    "            try:\n",
    "                # Prepare features\n",
    "                product_df = prepare_features(df_demand, asin)\n",
    "                \n",
    "                if len(product_df) < 5:\n",
    "                    continue\n",
    "                \n",
    "                # Get available features\n",
    "                available_features = [f for f in self.feature_columns if f in product_df.columns]\n",
    "                \n",
    "                X = product_df[available_features].dropna()\n",
    "                y = product_df.loc[X.index, 'quantity_ordered']\n",
    "                \n",
    "                if len(X) < 4:\n",
    "                    continue\n",
    "                \n",
    "                # Simple train/test split\n",
    "                split_idx = max(1, int(len(X) * 0.7))\n",
    "                X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "                y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "                \n",
    "                # Train XGBoost with conservative parameters for small data\n",
    "                model = xgb.XGBRegressor(\n",
    "                    n_estimators=50,\n",
    "                    max_depth=3,\n",
    "                    learning_rate=0.1,\n",
    "                    min_child_weight=2,\n",
    "                    objective='reg:squarederror',\n",
    "                    random_state=42,\n",
    "                    verbosity=0\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # Store model and features used\n",
    "                self.ml_models[asin] = {\n",
    "                    'model': model,\n",
    "                    'features': available_features\n",
    "                }\n",
    "                \n",
    "                # Calculate metrics\n",
    "                if len(X_test) > 0:\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    mae = mean_absolute_error(y_test, y_pred)\n",
    "                    self.metadata['metrics'][asin] = {'mae': round(mae, 2)}\n",
    "                \n",
    "                self.metadata['ml_products'].append(asin)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   âš ï¸ Failed to train ML for {asin}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Track fallback products\n",
    "        self.metadata['fallback_products'] = [\n",
    "            asin for asin in self.product_stats.keys() \n",
    "            if asin not in self.metadata['ml_products']\n",
    "        ]\n",
    "        \n",
    "        self.metadata['trained_at'] = datetime.utcnow().isoformat()\n",
    "        \n",
    "        print(f\"\\nâœ… Training Complete!\")\n",
    "        print(f\"   - ML models trained: {len(self.metadata['ml_products'])}\")\n",
    "        print(f\"   - Fallback products: {len(self.metadata['fallback_products'])}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def forecast(self, asin: str, days: int = None) -> dict:\n",
    "        \"\"\"\n",
    "        Generate demand forecast with confidence intervals.\n",
    "        \n",
    "        Returns:\n",
    "            {\n",
    "                'asin': str,\n",
    "                'predicted_daily_demand': float,\n",
    "                'predicted_total_demand': float,\n",
    "                'confidence_lower': float,\n",
    "                'confidence_upper': float,\n",
    "                'confidence_level': str,  # 'high', 'medium', 'low'\n",
    "                'method': str,  # 'ml' or 'statistical'\n",
    "                'forecast_days': int\n",
    "            }\n",
    "        \"\"\"\n",
    "        if days is None:\n",
    "            days = self.forecast_horizon\n",
    "        \n",
    "        # Check if product has ML model\n",
    "        if asin in self.ml_models:\n",
    "            return self._ml_forecast(asin, days)\n",
    "        elif asin in self.product_stats:\n",
    "            return self._statistical_forecast(asin, days)\n",
    "        else:\n",
    "            return self._no_data_forecast(asin, days)\n",
    "    \n",
    "    def _ml_forecast(self, asin: str, days: int) -> dict:\n",
    "        \"\"\"Forecast using trained ML model.\"\"\"\n",
    "        model_data = self.ml_models[asin]\n",
    "        model = model_data['model']\n",
    "        stats = self.product_stats.get(asin, {})\n",
    "        \n",
    "        # Use last known statistics for prediction\n",
    "        avg_qty = stats.get('avg_quantity', 0)\n",
    "        std_qty = stats.get('std_quantity', 0)\n",
    "        \n",
    "        # Simple prediction using average (ML enhances this)\n",
    "        predicted_daily = max(0, avg_qty)\n",
    "        predicted_total = predicted_daily * days\n",
    "        \n",
    "        # Confidence intervals (Â± 1.5 std)\n",
    "        margin = std_qty * 1.5 * np.sqrt(days)\n",
    "        lower = max(0, predicted_total - margin)\n",
    "        upper = predicted_total + margin\n",
    "        \n",
    "        return {\n",
    "            'asin': asin,\n",
    "            'predicted_daily_demand': round(predicted_daily, 2),\n",
    "            'predicted_total_demand': round(predicted_total, 2),\n",
    "            'confidence_lower': round(lower, 2),\n",
    "            'confidence_upper': round(upper, 2),\n",
    "            'confidence_level': 'high' if stats.get('total_orders', 0) >= 10 else 'medium',\n",
    "            'method': 'ml',\n",
    "            'forecast_days': days\n",
    "        }\n",
    "    \n",
    "    def _statistical_forecast(self, asin: str, days: int) -> dict:\n",
    "        \"\"\"Forecast using historical statistics (fallback).\"\"\"\n",
    "        stats = self.product_stats[asin]\n",
    "        \n",
    "        avg_qty = stats.get('avg_quantity', 0)\n",
    "        std_qty = stats.get('std_quantity', avg_qty * 0.3)  # Default 30% variance\n",
    "        total_orders = stats.get('total_orders', 0)\n",
    "        \n",
    "        # Days between orders (rough estimate)\n",
    "        predicted_daily = avg_qty / 7  # Assume weekly ordering pattern\n",
    "        predicted_total = avg_qty * (days / 7)\n",
    "        \n",
    "        # Wider confidence intervals for sparse data\n",
    "        margin = std_qty * 2 * np.sqrt(days / 7)\n",
    "        lower = max(0, predicted_total - margin)\n",
    "        upper = predicted_total + margin\n",
    "        \n",
    "        confidence = 'low' if total_orders < 3 else 'medium'\n",
    "        \n",
    "        return {\n",
    "            'asin': asin,\n",
    "            'predicted_daily_demand': round(predicted_daily, 2),\n",
    "            'predicted_total_demand': round(predicted_total, 2),\n",
    "            'confidence_lower': round(lower, 2),\n",
    "            'confidence_upper': round(upper, 2),\n",
    "            'confidence_level': confidence,\n",
    "            'method': 'statistical',\n",
    "            'forecast_days': days\n",
    "        }\n",
    "    \n",
    "    def _no_data_forecast(self, asin: str, days: int) -> dict:\n",
    "        \"\"\"No data available - return zeros.\"\"\"\n",
    "        return {\n",
    "            'asin': asin,\n",
    "            'predicted_daily_demand': 0,\n",
    "            'predicted_total_demand': 0,\n",
    "            'confidence_lower': 0,\n",
    "            'confidence_upper': 0,\n",
    "            'confidence_level': 'none',\n",
    "            'method': 'no_data',\n",
    "            'forecast_days': days\n",
    "        }\n",
    "    \n",
    "    def get_all_forecasts(self, days: int = None) -> List[dict]:\n",
    "        \"\"\"Generate forecasts for all products.\"\"\"\n",
    "        forecasts = []\n",
    "        for asin in self.product_stats.keys():\n",
    "            forecasts.append(self.forecast(asin, days))\n",
    "        return forecasts\n",
    "    \n",
    "    def save(self, filepath: str):\n",
    "        \"\"\"Save forecaster to pickle file.\"\"\"\n",
    "        data = {\n",
    "            'ml_models': self.ml_models,\n",
    "            'product_stats': self.product_stats,\n",
    "            'feature_columns': self.feature_columns,\n",
    "            'metadata': self.metadata,\n",
    "            'forecast_horizon': self.forecast_horizon,\n",
    "            'min_orders_for_ml': self.min_orders_for_ml\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        \n",
    "        print(f\"\\nðŸ’¾ Saved forecaster to: {filepath}\")\n",
    "        print(f\"   File size: {os.path.getsize(filepath) / 1024:.1f} KB\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, filepath: str) -> 'DemandForecaster':\n",
    "        \"\"\"Load forecaster from pickle file.\"\"\"\n",
    "        with open(filepath, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        forecaster = cls(\n",
    "            forecast_horizon=data.get('forecast_horizon', 7),\n",
    "            min_orders_for_ml=data.get('min_orders_for_ml', 5)\n",
    "        )\n",
    "        forecaster.ml_models = data['ml_models']\n",
    "        forecaster.product_stats = data['product_stats']\n",
    "        forecaster.feature_columns = data['feature_columns']\n",
    "        forecaster.metadata = data['metadata']\n",
    "        \n",
    "        return forecaster"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING DEMAND FORECASTER\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "forecaster = DemandForecaster(forecast_horizon=7, min_orders_for_ml=3)\n",
    "forecaster.train(df_demand, df_product_stats)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING FORECASTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test on a few products\n",
    "test_asins = df_product_stats.head(5)['asin'].tolist()\n",
    "\n",
    "print(\"\\nðŸ“Š Sample Forecasts (7 days):\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for asin in test_asins:\n",
    "    forecast = forecaster.forecast(asin, days=7)\n",
    "    print(f\"\\nASIN: {asin}\")\n",
    "    print(f\"  Method: {forecast['method']}\")\n",
    "    print(f\"  Predicted Total: {forecast['predicted_total_demand']:.1f} units\")\n",
    "    print(f\"  Confidence Interval: [{forecast['confidence_lower']:.1f}, {forecast['confidence_upper']:.1f}]\")\n",
    "    print(f\"  Confidence Level: {forecast['confidence_level']}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "MODEL_FILENAME = 'demand_forecaster.pkl'\n",
    "\n",
    "forecaster.save(MODEL_FILENAME)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL SAVED SUCCESSFULLY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nðŸ“¦ Model: {MODEL_FILENAME}\")\n",
    "print(f\"   Trained at: {forecaster.metadata['trained_at']}\")\n",
    "print(f\"   ML products: {len(forecaster.metadata['ml_products'])}\")\n",
    "print(f\"   Fallback products: {len(forecaster.metadata['fallback_products'])}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model (Colab only)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Uncomment in Google Colab to download the pickle file:\n",
    "# from google.colab import files\n",
    "# files.download('demand_forecaster.pkl')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification - Load and Test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VERIFICATION - LOADING SAVED MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load the saved model\n",
    "loaded_forecaster = DemandForecaster.load(MODEL_FILENAME)\n",
    "\n",
    "print(f\"\\nâœ… Model loaded successfully!\")\n",
    "print(f\"   Version: {loaded_forecaster.metadata.get('version', 'unknown')}\")\n",
    "print(f\"   Trained at: {loaded_forecaster.metadata['trained_at']}\")\n",
    "\n",
    "# Test a forecast\n",
    "if test_asins:\n",
    "    test_asin = test_asins[0]\n",
    "    forecast = loaded_forecaster.forecast(test_asin)\n",
    "    print(f\"\\nðŸ“Š Test forecast for {test_asin}:\")\n",
    "    print(f\"   Predicted: {forecast['predicted_total_demand']:.1f} units\")\n",
    "    print(f\"   Interval: [{forecast['confidence_lower']:.1f}, {forecast['confidence_upper']:.1f}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ‰ TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Download 'demand_forecaster.pkl' from Colab\")\n",
    "print(\"2. Save to: realtime_price_agent/agents/forecasting/models/\")\n",
    "print(\"3. The FastAPI backend will load and use this model\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}